{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('efe_beyazperde_sentiment.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ehopl\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "final_cleaning = []\n",
    "tknzr = TweetTokenizer()\n",
    "df_test['result'] = df_test['text'].apply(lambda x: re.sub('[^ A-Za-zöğüşçı]+', ' ', x))\n",
    "stop_words = [\"hanımdan\", \"beyden\", \"hanıma\", \"beye\", \"ve\", \"beymen\", \"bey\", \"acaba\t\", \"altı\", \"altmış\", \"ama\", \"ancak\", \"arada\", \"artık\", \"asla\", \"aslında\", \"ayrıca\", \"az\", \"bana\", \"bazen\", \"bazı\", \"bazıları\", \"belki\", \"ben\", \"benden\", \"beni\", \"benim\", \"beri\", \"beş\", \"bile\", \"bilhassa\", \"bin\", \"bir\", \"biraz\", \"birçoğu\", \"birçok\", \"biri\", \"birisi\", \"birkaç\", \"birşey\", \"biz\", \"bizden\", \"bize\", \"bizi\", \"bizim\", \"böyle\", \"böylece\", \"bu\", \"buna\", \"bunda\", \"bundan\", \"bunlar\", \"bunları\", \"bunların\", \"bunu\", \"bunun\", \"burada\", \"bütün\", \"çoğu\", \"çoğunu\", \"çok\", \"çünkü\", \"da\", \"daha\", \"dahi\", \"dan\", \"de\", \"defa\", \"diğer\", \"diğeri\", \"diğerleri\", \"diye\", \"doksan\", \"dokuz\", \"dolayı\", \"dolayısıyla\", \"dört\", \"e\", \"edecek\", \"eden\", \"ederek\", \"edilecek\", \"ediliyor\", \"edilmesi\", \"ediyor\", \"eğer\", \"elbette\", \"elli\", \"en\", \"etmesi\", \"etti\", \"ettiği\", \"ettiğini\", \"fakat\", \"falan\", \"filan\", \"gene\", \"gereği\", \"gerek\", \"gibi\", \"göre\", \"hala\", \"halde\", \"halen\", \"hangi\", \"hangisi\", \"hani\", \"hatta\", \"hem\", \"henüz\", \"hep\", \"hepsi\", \"her\", \"herhangi\", \"herkes\", \"herkese\", \"herkesi\", \"herkesin\", \"hiç\", \"hiçbir\", \"hiçbiri\", \"i\", \"ı\", \"için\", \"içinde\", \"iki\", \"ile\", \"ilgili\", \"ise\", \"işte\", \"itibaren\", \"itibariyle\", \"kaç\", \"kadar\", \"karşın\", \"kendi\", \"kendilerine\", \"kendine\", \"kendini\", \"kendisi\", \"kendisine\", \"kendisini\", \"kez\", \"ki\", \"kim\", \"kime\", \"kimi\", \"kimin\", \"kimisi\", \"kimse\", \"kırk\", \"madem\", \"mi\", \"mı\", \"milyar\", \"milyon\", \"mu\", \"mü\", \"nasıl\", \"ne\", \"neden\", \"nedenle\", \"nerde\", \"nerede\", \"nereye\", \"neyse\", \"niçin\", \"nin\", \"nın\", \"niye\", \"nun\", \"nün\", \"o\", \"öbür\", \"olan\", \"olarak\", \"oldu\", \"olduğu\", \"olduğunu\", \"olduklarını\", \"olmadı\", \"olmadığı\", \"olmak\", \"olması\", \"olmayan\", \"olmaz\", \"olsa\", \"olsun\", \"olup\", \"olur\", \"olursa\", \"oluyor\", \"on\", \"ön\", \"ona\", \"önce\", \"ondan\", \"onlar\", \"onlara\", \"onlardan\", \"onları\", \"onların\", \"onu\", \"onun\", \"orada\", \"öte\", \"ötürü\", \"otuz\", \"öyle\", \"oysa\", \"pek\", \"rağmen\", \"sana\", \"sanki\", \"şayet\", \"şekilde\", \"sekiz\", \"seksen\", \"sen\", \"senden\", \"seni\", \"senin\", \"şey\", \"şeyden\", \"şeye\", \"şeyi\", \"şeyler\", \"şimdi\", \"siz\", \"sizden\", \"size\", \"sizi\", \"sizin\", \"sonra\", \"şöyle\", \"şu\", \"şuna\", \"şunları\", \"şunu\", \"ta\", \"tabii\", \"tam\", \"çalışan\", \"çalışanlar\", \"çalışanlardan\", \"tamam\", \"tamamen\", \"tarafından\", \"trilyon\", \"tüm\", \"tümü\", \"u\", \"ü\", \"üç\", \"un\", \"ün\", \"üzere\", \"var\", \"vardı\", \"ve\", \"veya\", \"ya\", \"yani\", \"yapacak\", \"yapılan\", \"yapılması\", \"yapıyor\", \"yapmak\", \"yaptı\", \"yaptığı\", \"yaptığını\", \"yaptıkları\", \"ye\", \"yedi\", \"yerine\", \"yetmiş\", \"yi\", \"yı\", \"yine\", \"yirmi\", \"yoksa\", \"yu\", \"yüz\", \"zaten\", \"zira\"]\n",
    "for sentence in df_test['result']:\n",
    "    common = set(tknzr.tokenize(sentence)).intersection(stop_words)\n",
    "    final_token_list = (list(set(tknzr.tokenize(sentence))- common))\n",
    "    final_list = ' '.join(final_token_list)\n",
    "    final_cleaning.append(final_list)\n",
    "df_test.insert(len(df_test.columns),\"stemmed\", final_cleaning, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_test['stemmed'],df_test['target'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(df_test['stemmed'])\n",
    "training_features = vectorizer.transform(df_test['stemmed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 11}\n",
      "0.6507301460292059\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "#create new a knn model\n",
    "knn2 = KNeighborsClassifier()\n",
    "#create a dictionary of all values we want to test for n_neighbors\n",
    "param_grid = {'n_neighbors': np.arange(1, 25)}\n",
    "#use gridsearch to test all values for n_neighbors\n",
    "knn_gscv = GridSearchCV(knn2, param_grid, cv=5)\n",
    "#fit model to data\n",
    "knn_gscv.fit(training_features, df_test['target'])\n",
    "#check top performing n_neighbors value\n",
    "print(knn_gscv.best_params_)\n",
    "#check mean score for the top performing value of n_neighbors\n",
    "print(knn_gscv.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
