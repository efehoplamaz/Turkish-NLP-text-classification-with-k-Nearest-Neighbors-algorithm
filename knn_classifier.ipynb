{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the excel file that has been formed by normalizing the text and removing the punctuations, numbers and stop words.\n",
    "df = pd.read_excel('...xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: removing the texts which are classified neutral will increase the accuracy of the prediction\n",
    "df = df[df.target !=\"Neutral\"]\n",
    "# dropping unnecessary columns\n",
    "df.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many data we have for each class\n",
    "df.groupby(\"target\").nunique(\"fixed_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping empty rows and saving to dataframe again\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows the columns of the dataframe and how many objects stored in the columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after dropping the elements using dropna, reset the indexes\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "tfidf_vectorizer.fit(df['fixed_text'])\n",
    "tfidf_training_features = tfidf_vectorizer.transform(df['fixed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "count_vectorizer.fit(df['fixed_text'])\n",
    "count_training_features = count_vectorizer.transform(df['fixed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_results(vectorized_matrix, df):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(vectorized_matrix,df['target'], test_size=0.2, random_state=0)\n",
    "    knn = KNeighborsClassifier()\n",
    "    #create a dictionary of all values we want to test for n_neighbors\n",
    "    param_grid = {'n_neighbors': np.arange(1, 10)}\n",
    "    #use gridsearch to test all values for n_neighbors\n",
    "    knn_gscv = GridSearchCV(knn, param_grid, cv=5)\n",
    "    #fit model to data\n",
    "    knn_gscv.fit(vectorized_matrix, df['target'])\n",
    "    #check top performing n_neighbors value\n",
    "    optimal_k_value = knn_gscv.best_params_['n_neighbors']\n",
    "    print('The optimal k value is: ' + str(optimal_k_value.item()))\n",
    "    #check mean score for the top performing value of n_neighbors\n",
    "    #print(knn_gscv.best_score_)\n",
    "    classifier = KNeighborsClassifier(n_neighbors= optimal_k_value.item())\n",
    "    classifier.fit(X_train,Y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(f1_score(Y_test,y_pred, average='macro'))\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    print(accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-nn with using TF-IDF vectorization technique\n",
    "knn_results(tfidf_training_features, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-nn with using TF(countvectorizer) vectorization technique\n",
    "knn_results(count_training_features, df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
